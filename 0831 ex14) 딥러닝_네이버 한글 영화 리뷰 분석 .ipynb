{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### 목표\n","- 네이버 영화 리뷰의 긍정, 부정을 예측하는 순환 신경망 모델을 만들어보자!\n","- 학습용 데이터가 아닌 실제 리뷰(텍스트) 데이터를 전처리해서 신경망에 넣어보자!"],"metadata":{"id":"JFjCq9FSFuzq"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"metadata":{"id":"iEDYDxVTFuG6","executionInfo":{"status":"ok","timestamp":1693531280309,"user_tz":-540,"elapsed":677,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"id":"Puscms7FCWni","colab":{"base_uri":"https://localhost:8080/"},"outputId":"671ff027-43fc-4325-b6c9-2a5b5c999008","executionInfo":{"status":"ok","timestamp":1693531285077,"user_tz":-540,"elapsed":4389,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n","    return self.__dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n","    raise AttributeError(attr)\n","AttributeError: _DistInfoDistribution__dep_map\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 184, in __init__\n","    self[name] = toklist[0]\n","TypeError: 'int' object is not subscriptable\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n","    conflicts = self._determine_conflicts(to_install)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n","    return check_install_conflicts(to_install)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n","    package_set, _ = create_package_set_from_installed()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n","    dependencies = list(dist.iter_dependencies())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n","    return self._dist.requires(extras)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n","    dm = self._dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n","    self.__dep_map = self._compute_dependencies()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n","    reqs.extend(parse_requirements(req))\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n","    super(Requirement, self).__init__(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n","    req = REQUIREMENT.parseString(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n","    loc, tokens = self._parse(instring, 0)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 862, in _parseNoCache\n","    ret_tokens = ParseResults(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 184, in __init__\n","    self[name] = toklist[0]\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n","    logger.debug(\"Exception information:\", exc_info=True)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n","    self._log(DEBUG, msg, args, **kwargs)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n","    self.emit(record)\n","  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n","    logging.FileHandler.emit(self, record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n","    StreamHandler.emit(self, record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n","    return fmt.format(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n","    formatted = super().format(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n","    record.exc_text = self.formatException(record.exc_info)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n","    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n","  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n","    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n","  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n","    self.stack = StackSummary.extract(\n","  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n","    f.line\n","  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n","    self._line = linecache.getline(self.filename, self.lineno)\n","  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n","    lines = getlines(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n","    return updatecache(filename, module_globals)\n","  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n","    with tokenize.open(fullname) as fp:\n","  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n","    encoding, lines = detect_encoding(buffer.readline)\n","  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n","    first = read_or_stop()\n","  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n","    return readline()\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/17. SW캠프 데이터 비즈니스 과정"],"metadata":{"id":"gJ-y2y6YCWlK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"54205f4a-6b59-49f4-fd24-d549d4fbaa2b","executionInfo":{"status":"ok","timestamp":1693531285077,"user_tz":-540,"elapsed":13,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/17. SW캠프 데이터 비즈니스 과정'\n","/content\n"]}]},{"cell_type":"code","source":["df_train = pd.read_csv('data/ratings_train.txt', delimiter='\\t')\n","df_test = pd.read_csv('data/ratings_test.txt', delimiter='\\t')"],"metadata":{"id":"w9L9uhakA6kZ","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"error","timestamp":1693531285637,"user_tz":-540,"elapsed":568,"user":{"displayName":"이수현","userId":"14585987872054362818"}},"outputId":"cc5875fb-d984-4cf3-e167-ebcef3e245fa"},"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3dddcad5deff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/ratings_train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/ratings_test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ratings_train.txt'"]}]},{"cell_type":"code","source":["df_train"],"metadata":{"id":"bGoLqEAIA6hr","executionInfo":{"status":"aborted","timestamp":1693531285638,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.info()"],"metadata":{"id":"UcY4hL3GA6e8","executionInfo":{"status":"aborted","timestamp":1693531285638,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test.info()"],"metadata":{"id":"_t-m_ZZbA6cJ","executionInfo":{"status":"aborted","timestamp":1693531285638,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 결측치가 존재하는 행 제거\n","df_train.dropna(inplace=True)\n","df_test.dropna(inplace=True)"],"metadata":{"id":"qFZcKU_DA6Za","executionInfo":{"status":"aborted","timestamp":1693531285639,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.info()"],"metadata":{"id":"WIWnMi5wA6Wp","executionInfo":{"status":"aborted","timestamp":1693531285639,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 문제, 정답 데이터로 분리"],"metadata":{"id":"CCFKpH819uig"}},{"cell_type":"code","source":["# id 컬럼은 분석에 큰 영향이 없을 것 같으니 제외\n","X_train = df_train['document']\n","y_train = df_train['label']\n","X_test = df_test['document']\n","y_test = df_test['label']\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"],"metadata":{"id":"LdMsf5fpA6T6","executionInfo":{"status":"aborted","timestamp":1693531285639,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"id":"Aan_StB_9wyz","executionInfo":{"status":"aborted","timestamp":1693531285639,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### konlpy의 형태소 분석기(문장을 형태소로 분리해주는 도구) 종류\n","- Kkma : 서울대학교 데이터 랩에서 개발, 일반적인 성능은 좋으나 분석시간이 konlpy 형태소 분석기 중 가장 오래걸림\n","- Okt : twitter에서 개발, twitter 데이터를 기반으로 형태소를 추출하기 때문에 인터넷 텍스트에 특화되어 있고, 비표준어, 비속어 등이 포함되어 있는 정제되지 않은 데이터 처리에 강함 + 추가로 konlpy 형태소 분석기 중 유일하게 stemming(어간추출) 기능을 포함하고 있음, 속도는 준수하나 동음이의어 처리가 어렵고, 분석 범주가 다른 형태소 분석기에 비해 좁은 단점\n","- Komoran : Shineware에서 개발, 오탈자에 대해 분석 품질은 좋으나 띄워쓰기가 없는 문장을 분석하는데 좋지 않음\n","- Hannanum : KAIST에서 개발, 띄워쓰기가 없는 문장에서 분석 품질이 좋지 않음\n","- Mecab : 일본어용 형태소 분석기를 한국어에 사용할 수 있도록 수정한 분석기, 속도가 5개 중 가장 빠르나 window에서 설치가 힘들고 동음이의어 처리에 취약함"],"metadata":{"id":"D3nIVDk0-oHv"}},{"cell_type":"markdown","source":["위 다섯개 형태소 분석기 모두 nouns, morphs, pos 함수를 지원\n","- nouns : 주어진 문장의 명사를 추출\n","- morphs : 주어진 문장의 형태소를 추출\n","- pos : 주어진 문장의 형태소와 각 단어의 품사를 식별하여 태그를 추가해 함께 출력(품사 태깅)"],"metadata":{"id":"YXLCWIMRAiTW"}},{"cell_type":"code","source":["# 인터넷 영화 리뷰를 분석하는데 적합한 Okt 형태소 분석기 임포트\n","from konlpy.tag import Okt\n","from tqdm import tqdm\n","import pickle"],"metadata":{"id":"UGT-nxb79wwX","executionInfo":{"status":"aborted","timestamp":1693531285639,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["okt = Okt()"],"metadata":{"id":"TD4Yj_5q9wuO","executionInfo":{"status":"aborted","timestamp":1693531285640,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 형태소 추출 후 공백을 주면서 각각의 문장으로 연결(뒤에 이어질 토큰화에서 공백 기준으로 토큰화시켜주기 위함)\n","# 긴 문장이나 띄워쓰기가 잘 되어있지 않은 경우 토큰화의 성능이 좋지 않기 때문에 문장을 형태소로\n","# 분리한 후 공백을 줘서 다시 문장으로 재구성함!\n","X_train_morphs = [' '.join(okt.morphs(doc)) for doc in tqdm(X_train)]\n","X_test_morphs = [' '.join(okt.morphs(doc)) for doc in tqdm(X_test)]"],"metadata":{"id":"fKx7gGOo9wr1","executionInfo":{"status":"aborted","timestamp":1693531285640,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_morphs"],"metadata":{"id":"0VnX_MFE9wps","executionInfo":{"status":"aborted","timestamp":1693531285640,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pickle 파일로 저장(colab 재접속 시 바로 가공된 데이터를 사용하기 위함)\n","# pickle : 텍스트 파일이 아닌 데이터의 자료 구조 형태를 그대로 저장하거나 불러오는 모듈\n","with open('data/X_train_morphs.pkl', 'wb') as f :\n","    pickle.dump(X_train_morphs, f)\n","\n","with open('data/X_test_morphs.pkl', 'wb') as f :\n","    pickle.dump(X_test_morphs, f)"],"metadata":{"id":"6kqYyTXhI1pE","executionInfo":{"status":"aborted","timestamp":1693531285640,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pickle 파일 로드(형태소로 분리되어 문장화 되어있는 상태 그대로 로드)\n","with open('data/X_train_morphs.pkl', 'rb') as f :\n","    X_train = pickle.load(f)\n","\n","with open('data/X_test_morphs.pkl', 'rb') as f :\n","    X_test = pickle.load(f)"],"metadata":{"id":"XACBPtkmI1nB","executionInfo":{"status":"aborted","timestamp":1693531285640,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### keras에서 지원하는 한글을 포함하는 토크나이저(Tokenizer)를 사용해서 토큰화 시켜보자!\n","\n","- keras 지원 Tokenizer 특징 -\n","- 1) 공백(띄워쓰기) 기준으로 토큰화\n","- 2) 빈도수 기준으로 자동 레이블 인코딩(로이터 뉴스 데이터 처럼!)\n","- 3) 기본적인 한국어 정규표현식이 적용"],"metadata":{"id":"lGh5w6RnKnbV"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer"],"metadata":{"id":"bb-o0LbuI1k1","executionInfo":{"status":"aborted","timestamp":1693531285640,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer()"],"metadata":{"id":"gXbCu8XCI1iq","executionInfo":{"status":"aborted","timestamp":1693531285640,"user_tz":-540,"elapsed":11,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 토크나이저로 학습 후 단어사전(BoW) 생성\n","tokenizer.fit_on_texts(X_train)"],"metadata":{"id":"_c3fy-Bk9wnV","executionInfo":{"status":"aborted","timestamp":1693531285641,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 토큰들의 빈도수에 따른 인코딩 결과(랭킹) 출력\n","tokenizer.word_index\n","\n","# '이' 라는 토큰이 가장 많이 사용되었으며 1로 인코딩 됨"],"metadata":{"id":"XOKUVuftA6Ra","executionInfo":{"status":"aborted","timestamp":1693531285641,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 토큰이 얼마나 사용되었는지 빈도수 출력\n","tokenizer.word_counts"],"metadata":{"id":"W-dbZQPRL97o","executionInfo":{"status":"aborted","timestamp":1693531285641,"user_tz":-540,"elapsed":12,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# BoW에 있는 전체 토큰 개수\n","len(tokenizer.word_index)"],"metadata":{"id":"RZliaoj-L95H","executionInfo":{"status":"aborted","timestamp":1693531285642,"user_tz":-540,"elapsed":13,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 빈도가 너무 낮은 토큰들을 제거해보자\n","- 정렬을 이용해서 단어의 빈도수를 확인하고 순위까지 보자!"],"metadata":{"id":"j2jtupErNBI9"}},{"cell_type":"code","source":["tokenizer.word_counts.items()"],"metadata":{"id":"hjU5No5eL92-","executionInfo":{"status":"aborted","timestamp":1693531285642,"user_tz":-540,"elapsed":13,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(tokenizer.word_counts.items(),\n","                  columns=['Token', 'Count']\n","                  )\n","\n","df.head()"],"metadata":{"id":"xHk9IMYBL90V","executionInfo":{"status":"aborted","timestamp":1693531285642,"user_tz":-540,"elapsed":13,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 정렬 후 출력되는 index는 의미가 없으므로 reset_index로 현재 values 상태 그대로 다시 인데스를 매겨줌\n","# 기존 index는 컬럼으로 들어오지만 drop=True로 없애줌\n","df_sorted = df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n","df_sorted"],"metadata":{"id":"1tmXSOIjRKrC","executionInfo":{"status":"aborted","timestamp":1693531285643,"user_tz":-540,"elapsed":13,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 등장 빈도가 20번 미만인 데이터를 제거하자(최소 20번은 나와야 BoW에 저장하기!)\n","df_sorted[df_sorted['Count'] < 20]"],"metadata":{"id":"3W-JqngQRKor","executionInfo":{"status":"aborted","timestamp":1693531285643,"user_tz":-540,"elapsed":13,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# num_words : 원하는 인덱스 번호까지만 사용(학습 데이터에서 빈도수가 높은 7851개의 데이터만 사용하겠다는 뜻)\n","final_tokenizer = Tokenizer(num_words=7851)"],"metadata":{"id":"43qsjuqcRKmL","executionInfo":{"status":"aborted","timestamp":1693531285643,"user_tz":-540,"elapsed":13,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_tokenizer.fit_on_texts(X_train)"],"metadata":{"id":"y0LAvsIlRKjj","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# texts_to_sequences : 토큰들을 인코딩 시킨 결과를 순서대로 리스트에 넣어줌\n","X_train_seq = final_tokenizer.texts_to_sequences(X_train)\n","X_test_seq = final_tokenizer.texts_to_sequences(X_test)"],"metadata":{"id":"PJwYscnpL9xk","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_seq\n","\n","# 다만 빈도수가 20회 미만인 데이터는 사용하지 않았기 때문에 단어가 부족한 리스트가 있을 수 있음"],"metadata":{"id":"j0EV570oL9u8","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 현재까지가 raw 데이터(리뷰 데이터)에서 1) 형태소 추출, 2) 토큰화+랭킹 순 인코딩, 3) 빈도수가 적은 단어 제외 까지 진행한 상태\n","- 한국어 같은 경우는 형태소 추출이나 토큰화 단계에서 조사나 접속사를 제거하면 되기 때문에 따로 정해진 불용어가 없음(직접 설정하고 싶다면 불용어 사전을 만들고 기존 데이터에서 not in으로 제거해주면 됨)"],"metadata":{"id":"d3Jjr_NkX7qi"}},{"cell_type":"markdown","source":["### 순환 신경망에 넣기 위해 리뷰 데이터의 시퀀스 길이를 알아보자!"],"metadata":{"id":"uBxUGVZ1Ywtt"}},{"cell_type":"code","source":["# X_train_seq에 있는 내부 리스트의 개수(시퀀스 길이)를 반환하여 리스트에 저장\n","X_train_len = [len(doc) for doc in X_train_seq]"],"metadata":{"id":"c7MbCq1pL9sm","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_len"],"metadata":{"id":"7UpWSY2fL9qM","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"최대값 :\", max(X_train_len))\n","print(\"최소값 :\", min(X_train_len))\n","print(\"평균값 :\", np.mean(X_train_len))\n","print(\"중앙값 :\", np.median(X_train_len))\n","\n","# 길이가 0개인 리뷰는 빈도수가 20회 미만인 단어들로만 이루어져 있어서 전부 없어짐"],"metadata":{"id":"cM6N7tl-L9ns","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 히스토그램으로 리뷰 길이의 분포를 확인해보자!\n","plt.hist(X_train_len, bins=10)\n","plt.xlabel('review_len')\n","plt.ylabel('review_count')\n","plt.show()"],"metadata":{"id":"sB_zcdHGL9lF","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","X_train_pad_seq = pad_sequences(X_train_seq, maxlen=15)\n","X_test_pad_seq = pad_sequences(X_test_seq, maxlen=15)"],"metadata":{"id":"eGrdlFhZL9ib","executionInfo":{"status":"aborted","timestamp":1693531285644,"user_tz":-540,"elapsed":14,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_pad_seq.shape, X_test_pad_seq.shape"],"metadata":{"id":"XAR3-EZTbJLu","executionInfo":{"status":"aborted","timestamp":1693531285645,"user_tz":-540,"elapsed":15,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_pad_seq[62]"],"metadata":{"id":"7CpSSrPBbJJh","executionInfo":{"status":"aborted","timestamp":1693531285645,"user_tz":-540,"elapsed":15,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 신경망 모델링\n","- 입력층에 임베딩 층 설정(nput_dim=7851 설정)\n","- 중간층에 LSTM층 설정\n","- 출력층 MLP\n","- loss, optimizer 고려\n","- validation 데이터 분리해서 학습\n","- modelcheckpoint(모델체크포인트), earlystopping(얼리스탑핑)\n","- 학습 결과 시각화\n","- test 데이터로 classification_report 출력"],"metadata":{"id":"V7pLUEdhbeS9"}},{"cell_type":"code","source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"metadata":{"id":"uXrnonvzbJHG","executionInfo":{"status":"ok","timestamp":1693531305169,"user_tz":-540,"elapsed":6260,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Dropout\n","from IPython.core.interactiveshell import validate\n","review_model = Sequential()"],"metadata":{"id":"LX-L3NvvbJEi","executionInfo":{"status":"ok","timestamp":1693531310750,"user_tz":-540,"elapsed":3505,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"UQtK_WhQU9HU","executionInfo":{"status":"aborted","timestamp":1693531285645,"user_tz":-540,"elapsed":15,"user":{"displayName":"이수현","userId":"14585987872054362818"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Dropout\n","from IPython.core.interactiveshell import validate\n","review_model = Sequential()\n","\n","review_model.add(Embedding(input_dim=7851, output_dim=50))\n","review_model.add(Dropout(0.3))\n","\n","# 학습시 과대적합을 방지하기 위해 매 epoch마다 랜덤하게 30%의 뉴런들의 학습을 비활성화 시킴\n","\n","review_model.add(LSTM(128, return_sequences=True))\n","review_model.add(LSTM(64))\n","\n","review_model.add(Dense(1, activation='sigmoid'))\n","\n","review_model.compile(loss='binary_crossentropy',\n","                     optimizer='Adam',\n","                     metrics=['acc']\n","                     )\n","\n","save_path = '/content/drive/MyDrive/Colab Notebooks/sw캠프 데이터 비지니스 과정/model/review_model_{epoch:03d}_{val_acc:.4f}.hdf5'\n","\n","mckp = ModelCheckpoint(filepath = save_path,\n","                       monitor='val_acc',\n","                       save_best_only=True,\n","                       mode='max',\n","                       verbose=1\n","                       )\n","\n","early = EarlyStopping(monitor='val_acc',\n","                       patience=5\n","                       )\n","\n","h = review_model.fit(X_train_pad_seq, y_train,\n","                     validation_split=0.2,\n","                     batch_size=128,\n","                     epochs=100,\n","                     callbacks=[mckp, early]\n","                     )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"id":"LUP932IuVRR3","executionInfo":{"status":"error","timestamp":1693531319456,"user_tz":-540,"elapsed":905,"user":{"displayName":"이수현","userId":"14585987872054362818"}},"outputId":"ec5b7beb-b38c-4c2f-bfb0-168035cb00d1"},"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c141cdc27446>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                        )\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m h = review_model.fit(X_train_pad_seq, y_train,\n\u001b[0m\u001b[1;32m     34\u001b[0m                      \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train_pad_seq' is not defined"]}]},{"cell_type":"code","source":["review_model.evaluate(X_test_pad_seq, y_test)"],"metadata":{"id":"EtMjhDUPVRPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre = review_model.predict(X_test_pad_seq)\n","pre"],"metadata":{"id":"og9Zvp7wVRNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이진 분류에서는 출력층 뉴런수가 1개이므로 0~1사이 확률값이 하나만 나오는데 이를 0 or 1 로 변환시켜줘야함\n","# pre 내부 값이 0.5보다 크면 True 출력, 아니면 False가 출력되는데 (파이썬에서는 True가 1, False가 0으로 인식)이를 정수로 반환\n","\n","pre_binary = (pre > 0.5).astype(int)\n","pre_binary"],"metadata":{"id":"8CXEYJKgVRK6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# 예측값을 변화시킨 결과가 0 또는 1이기 때문에 argmax를 사용할 필요 없음\n","\n","print(classification_report(y_test, pre_binary))"],"metadata":{"id":"v3utXKTVVRIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZwmJwSKDVRFi"},"execution_count":null,"outputs":[]}]}